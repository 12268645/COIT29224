# COIT29224 Evolutionary Computation
# Assignment 2
# Author: Brandon Peters
# Student Number: 12268645
# Unit Coordinator: Dr Umair Ullah Tariq

import numpy as np
import matplotlib.pyplot as plt
import copy
from typing import Callable

# Set seed for reproducibility
np.random.seed(42)

# Rastrigin fitness function
def rastrigin(X: np.ndarray) -> float:
    A = 10
    return A * len(X) + sum([(x ** 2 - A * np.cos(2 * np.pi * x)) for x in X])

# ========== (1+1)-ES ==========
class OnePlusOneES:
    def __init__(self, fitness_function: Callable[[np.ndarray], float], dimension=2, sigma=0.3, max_generations=500, bounds=(-5.12, 5.12)):
        self.fitness_function = fitness_function
        self.dimension = dimension
        self.sigma = sigma
        self.max_generations = max_generations
        self.bounds = bounds
        self.history = []

    def evolve(self):
        parent = np.random.uniform(self.bounds[0], self.bounds[1], self.dimension)
        parent_fitness = self.fitness_function(parent)
        for gen in range(self.max_generations):
            offspring = parent + np.random.normal(0, self.sigma, self.dimension)
            offspring = np.clip(offspring, self.bounds[0], self.bounds[1])
            offspring_fitness = self.fitness_function(offspring)
            if offspring_fitness < parent_fitness:
                parent = offspring
                parent_fitness = offspring_fitness
            self.history.append(parent_fitness)
        return parent, parent_fitness

# ========== (1+1)-ES with 1/5th Rule ==========
class OnePlusOneES_1FifthRule:
    def __init__(self, fitness_function: Callable[[np.ndarray], float], dimension=2, sigma=0.3, max_generations=500, bounds=(-5.12, 5.12), adapt_interval=10, adapt_const=0.85):
        self.fitness_function = fitness_function
        self.dimension = dimension
        self.sigma = sigma
        self.max_generations = max_generations
        self.bounds = bounds
        self.adapt_interval = adapt_interval
        self.adapt_const = adapt_const
        self.history = []

    def evolve(self):
        parent = np.random.uniform(self.bounds[0], self.bounds[1], self.dimension)
        parent_fitness = self.fitness_function(parent)
        success_count = 0
        for gen in range(self.max_generations):
            offspring = parent + np.random.normal(0, self.sigma, self.dimension)
            offspring = np.clip(offspring, self.bounds[0], self.bounds[1])
            offspring_fitness = self.fitness_function(offspring)
            if offspring_fitness < parent_fitness:
                parent = offspring
                parent_fitness = offspring_fitness
                success_count += 1
            self.history.append(parent_fitness)
            if (gen + 1) % self.adapt_interval == 0:
                success_rate = success_count / self.adapt_interval
                if success_rate > 0.2:
                    self.sigma /= self.adapt_const
                elif success_rate < 0.2:
                    self.sigma *= self.adapt_const
                success_count = 0
        return parent, parent_fitness

# ========== CMA-ES ==========
class StrategyOnePlusLambda:
    def __init__(self, parent, sigma, lambda_=4):
        self.parent = np.array(parent)
        self.sigma = sigma
        self.dim = len(parent)
        self.lambda_ = lambda_
        self.C = np.identity(self.dim)
        self.A = np.identity(self.dim)
        self.pc = np.zeros(self.dim)
        self.psucc = 0.0
        self.d = 1.0 + self.dim / (2.0 * self.lambda_)
        self.ptarg = 1.0 / (5 + np.sqrt(self.lambda_) / 2.0)
        self.cp = self.ptarg * self.lambda_ / (2 + self.ptarg * self.lambda_)
        self.cc = 2.0 / (self.dim + 2.0)
        self.ccov = 2.0 / (self.dim ** 2 + 6.0)
        self.pthresh = 0.44

    def generate(self):
        arz = np.random.standard_normal((self.lambda_, self.dim))
        return self.parent + self.sigma * np.dot(arz, self.A.T)

    def update(self, population, fitnesses):
        best_idx = np.argmin(fitnesses)
        best_offspring = population[best_idx]
        x_step = (best_offspring - self.parent) / self.sigma
        if fitnesses[best_idx] < rastrigin(self.parent):
            self.parent = copy.deepcopy(best_offspring)
            self.psucc = (1 - self.cp) * self.psucc + self.cp
        else:
            self.psucc = (1 - self.cp) * self.psucc
        if self.psucc < self.pthresh:
            self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc)) * x_step
            self.C = (1 - self.ccov) * self.C + self.ccov * np.outer(self.pc, self.pc)
        else:
            self.pc = (1 - self.cc) * self.pc
            self.C = (1 - self.ccov) * self.C + self.ccov * (np.outer(self.pc, self.pc) + self.cc * (2 - self.cc) * self.C)
        self.sigma *= np.exp((self.psucc - self.ptarg) / ((1.0 - self.ptarg) * self.d))

# ================= RUN EXPERIMENTS =================

# (1+1)-ES
es = OnePlusOneES(fitness_function=rastrigin)
sol_es, fit_es = es.evolve()
plt.plot(es.history)
plt.title("(1+1)-ES Convergence")
plt.xlabel("Generation")
plt.ylabel("Fitness")
plt.grid(True)
plt.show()
print("Best solution (1+1-ES):", sol_es)
print("Best fitness (1+1-ES):", fit_es)

# (1+1)-ES with 1/5th Rule
es_1fifth = OnePlusOneES_1FifthRule(fitness_function=rastrigin)
sol_1fifth, fit_1fifth = es_1fifth.evolve()
plt.plot(es_1fifth.history)
plt.title("(1+1)-ES with 1/5th Rule Convergence")
plt.xlabel("Generation")
plt.ylabel("Fitness")
plt.grid(True)
plt.show()
print("Best solution (adaptive):", sol_1fifth)
print("Best fitness (adaptive):", fit_1fifth)

# CMA-ES
np.random.seed(42)
parent = np.random.uniform(-5.12, 5.12, 2)
cma = StrategyOnePlusLambda(parent=parent, sigma=0.5, lambda_=4)
history_cma = []
for _ in range(300):  # more generations for better convergence
    offspring = cma.generate()
    fitnesses = [rastrigin(ind) for ind in offspring]
    cma.update(offspring, fitnesses)
    history_cma.append(rastrigin(cma.parent))
plt.plot(history_cma)
plt.title("CMA-ES Convergence")
plt.xlabel("Generation")
plt.ylabel("Fitness")
plt.grid(True)
plt.show()
print("Best CMA-ES solution:", cma.parent)
print("Best CMA-ES fitness:", history_cma[-1])
